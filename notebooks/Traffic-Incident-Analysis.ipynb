{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5515985b-347f-43a4-9f68-c008e80d7df2",
   "metadata": {},
   "source": [
    "# 🚦 Traffic Incident Analysis\n",
    "\n",
    "This project explores traffic incident patterns in the City of Calgary using public incident data. We analyze spatial and temporal trends in Calgary using data mining techniques, spatial clustering, and temporal trend analysis with machine learning\n",
    "\n",
    "## ✨ Project Goals\n",
    "- Detect spatial hotspots using clustering (DBSCAN)\n",
    "- Analyze incident frequency by hour, weekday, and season\n",
    "- Predict incident counts with Random Forest Regression\n",
    "\n",
    "## 📂 Structure\n",
    "- `data/`: Raw and cleaned datasets\n",
    "- `notebooks/`: JupyterLab analysis steps\n",
    "- `output/`: Visualizations and results\n",
    "\n",
    "## 🛠️ Tools\n",
    "- Python, Pandas, Matplotlib, Seaborn, Scikit-learn, Folium\n",
    "- JupyterLab for development\n",
    "- GitHub for version control\n",
    "\n",
    "## 📍 Data Source\n",
    "[City of Calgary Open Data Portal - Traffic Incidents](https://data.calgary.ca/Transportation-Transit/Traffic-Incidents/35ra-9556)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5712978-7872-4f16-b084-62b2a6895a41",
   "metadata": {},
   "source": [
    "# Step 1: Load and Preprocess Traffic Incident Data\n",
    "\n",
    "In this step, we will:\n",
    "- Import the traffic incidents dataset.\n",
    "- Clean the data by removing missing or invalid values.\n",
    "- Extract useful temporal features (hour, day of the week, month, season).\n",
    "- Save the cleaned dataset for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bb5c9b-b759-4a09-8c8d-cfd4d35643cf",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c332734b-fca0-4f25-8009-0bac338c9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7796111-dac6-400e-abf7-9621665566ad",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "The dataset is update till March 31st 2025 and downloaded from the [City of Calgary Open Data Portal](https://data.calgary.ca/Transportation-Transit/Traffic-Incidents/35ra-9556), and stored in the `data/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03808634-0f7a-467b-aea1-296dff35dd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (53788, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['INCIDENT INFO', 'DESCRIPTION', 'START_DT', 'MODIFIED_DT', 'QUADRANT',\n",
       "       'Longitude', 'Latitude', 'Count', 'id', 'Point'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Traffic_Incidents_20250331.csv')\n",
    "\n",
    "# Preview shape and column names\n",
    "print(\"Shape:\", df.shape)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe13a6-11f5-4e82-ba80-c06632bd2fcf",
   "metadata": {},
   "source": [
    "## Clean the Dataset\n",
    "\n",
    "- Convert `START_DT` to datetime format\n",
    "- Drop rows with missing or invalid coordinates.\n",
    "- Filter out invalid lat/long points outside Calgary's range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b38b6aa-faf0-43c0-8377-6a804c81504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert START_DT to datetime\n",
    "df['START_DT'] = pd.to_datetime(df['START_DT'])\n",
    "\n",
    "# Drop rows with missing latitude or longitude\n",
    "df.dropna(subset=['Latitude', 'Longitude'], inplace=True)\n",
    "\n",
    "# Filtering for valid Calgary coordinates\n",
    "df = df[(df['Latitude'] > 50) & (df['Latitude'] < 52)]\n",
    "df = df[(df['Longitude'] < -113) & (df['Longitude'] > -115)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507c903f-3025-468a-a082-dd31ce857047",
   "metadata": {},
   "source": [
    "## Extract Temporal Features\n",
    "\n",
    "We'll derive additional columns for:\n",
    "- Hour of the day\n",
    "- Day of the week\n",
    "- Month of the year\n",
    "- Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9bcb4fd7-1978-495d-93dd-68b73020f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-based features\n",
    "df['hour'] = df['START_DT'].dt.hour\n",
    "df['day_of_week'] = df['START_DT'].dt.dayofweek  # 0 = Monday\n",
    "df['month'] = df['START_DT'].dt.month\n",
    "df['season'] = df['month'].map({\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "    3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "    6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "    9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a648961-14f1-4bf8-9fd6-476ea8d4fd21",
   "metadata": {},
   "source": [
    "## Save the Cleaned Dataset\n",
    "\n",
    "We'll export the preprocessed data to a new CSV file for use in analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3eeda4b0-fabf-4ded-89c6-e66a1b021201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('../data/Traffic_Incidents_Cleaned.csv', index=False)\n",
    "print(\"✅ Cleaned data saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a14af-1e6d-4f60-be0c-5072ac7237a1",
   "metadata": {},
   "source": [
    "## Preprocessed Data Summary\n",
    "\n",
    "Let's inspect the cleaned dataset before proceeding with analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6fc13d8b-dc0e-48c1-adb5-73efacc9c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53788 entries, 0 to 53787\n",
      "Data columns (total 14 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   INCIDENT INFO  53788 non-null  object \n",
      " 1   DESCRIPTION    53786 non-null  object \n",
      " 2   START_DT       53788 non-null  object \n",
      " 3   MODIFIED_DT    39731 non-null  object \n",
      " 4   QUADRANT       39729 non-null  object \n",
      " 5   Longitude      53788 non-null  float64\n",
      " 6   Latitude       53788 non-null  float64\n",
      " 7   Count          53788 non-null  int64  \n",
      " 8   id             53788 non-null  object \n",
      " 9   Point          53788 non-null  object \n",
      " 10  hour           53788 non-null  int64  \n",
      " 11  day_of_week    53788 non-null  int64  \n",
      " 12  month          53788 non-null  int64  \n",
      " 13  season         53788 non-null  object \n",
      "dtypes: float64(2), int64(4), object(8)\n",
      "memory usage: 5.7+ MB\n",
      "\n",
      "Missing values:\n",
      " INCIDENT INFO        0\n",
      "DESCRIPTION          2\n",
      "START_DT             0\n",
      "MODIFIED_DT      14057\n",
      "QUADRANT         14059\n",
      "Longitude            0\n",
      "Latitude             0\n",
      "Count                0\n",
      "id                   0\n",
      "Point                0\n",
      "hour                 0\n",
      "day_of_week          0\n",
      "month                0\n",
      "season               0\n",
      "dtype: int64\n",
      "\n",
      "Seasons: ['Summer' 'Spring' 'Winter' 'Fall']\n",
      "Days of Week (0 = Monday): [1 0 3 4 2 5 6]\n",
      "Unique months: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Hours: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "# Reload the cleaned data just to be sure\n",
    "df = pd.read_csv('../data/Traffic_Incidents_Cleaned.csv')\n",
    "\n",
    "# Show first few rows\n",
    "df.head()\n",
    "\n",
    "# Check structure\n",
    "df.info()\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check unique values in key features\n",
    "print(\"\\nSeasons:\", df['season'].unique())\n",
    "print(\"Days of Week (0 = Monday):\", df['day_of_week'].unique())\n",
    "print(\"Unique months:\", sorted(df['month'].unique()))\n",
    "print(\"Hours:\", sorted(df['hour'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17477a-1c5a-4f1c-9ecc-33042d939592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
